\chapter{Experiments}
\label{chapter05}

\section{Comparing AIs against each other}

To compare the strength of our AIs against each other, we simulated 1000 randomly generated games
and had the AIs play against each other. Both teams were generated at random and there was no step taken
to make them balanced. Instead, each AI played both sides of the match. See \autoref{tab:winrates} for results.

\begin{table}[h]
	\centering
	\begin{tabular}{|| c | c c c ||}
		\hline
		& MCTS & Rule & Random \\
		\hline\hline
		MCTS & N/A & 63\% & 88\% \\
		Rule & 37\%& N/A & 82\% \\
		Random & 12\% & 18\% & N/A \\
		\hline
	\end{tabular}
	\caption{Table showing win percentages over 1000 games between our different AI implementations.
	MCTS beats Random 88\% of the time, MCTS beats Rule 63\% of the time, and Rule beats Random 82\% of the time.}
	\label{tab:winrates}
\end{table}

As we can see, both MCTS and the Rule Based AI can beat our Random AI with a significant margin,
and MCTS can also consistently beat the Rule Based AI, despite playing for both generated teams.
From this we conclude that:

\begin{enumerate}
	\item A greedy aggressive strategy doesn't always win, which means the game mechanics are rich enough
	to reward strategic thinking.
	\item Thinking ahead (as MCTS does) provides enough value to be significant in terms of win rate.
\end{enumerate}

\missingfigure{vysledky jiny nez experiment}

\section{Participants}

The participants were all computer science students. All of them had at least
some experience with computer games, and were presented the mechanics of HexMage
before conducting the experiment.

\section{Experiment Design}

The goal of the experiment is to measure two things. One, if the generated
encounters are actually balanced. And two, if the AI is strong enough to pose a
challenge to the player. We will measure the overall winrate of the players,
and also compare how the AI did in games the player considered balanced.

The experiment consists of 20 different games of HexMage. All of the games are
played on the same map that was hand-designed beforehand. This was to allow the
participants to better get familiar with the game and think ahead. The games
are structured so that each player has 2 mages, each with 2 abilities. This was
to reduce the cognitive overhead for the participants and allow them to more easily
adjust to the 20 completely different scenarios.

The first 10 of the 20 games had the player team hand designed, and the
opponent (played by the AI) generated with our PCG algorithm. The remaining 10
games had both teams generated with no manual tweaks or changes. Having some of
the games hand designed allows us to show that the PCG algorithm can balance
against constraints that aren't completely random. A hand designed team might
have features that are rare in the search space. All of the games are played
against the MCTS based AI\@ with a fixed number of iterations.

\section{Questionnaire}

The questions were the following, answered on scale (1 - definitely no, to 7 - definitely yes), showing short codes for \autoref{tab:balance-corr} and \autoref{tab:difficulty-corr}

\begin{description}[]
	\item[Balanced:] The game balanced.
	\item[Challenge:] The game was challenging.
	\item[Unsure:] I wasn't sure who was going to win.
	\item[Smart:] The AI played smart.
	\item[Difficult:] The game was difficult.
	\item[Strategy:] The AI showed strategic thinking.
\end{description}

\section{Results}

As we can see in \autoref{tab:balance-corr}, the questions for balance strongly correlate.

\begin{table}[h]
	\centering
	\begin{tabular}{lrr}
		\toprule
		{} &  balanced &  unsure \\
		\midrule
		balanced &      1.00 &    0.73 \\
		unsure   &      0.73 &    1.00 \\
		\bottomrule
	\end{tabular}
	\caption{Correlation table between people who said the game was balanced and who were unsure about the result.}	
	\label{tab:balance-corr}
\end{table}

\begin{table}[h]
	\centering
	\begin{tabular}{lrrrr}
		\toprule
		{} &  challenge &  smart &  difficult &  strategy \\
		\midrule
		challenge &       1.00 &   0.61 &       0.46 &      0.63 \\
		smart     &       0.61 &   1.00 &       0.39 &      0.82 \\
		difficult &       0.46 &   0.39 &       1.00 &      0.39 \\
		strategy  &       0.63 &   0.82 &       0.39 &      1.00 \\
		\bottomrule
	\end{tabular}
	\caption{Correlation table between people who said the game was challenging, the AI was smart, the game was difficult to play and the AI showed strategic behavior.}
	\label{tab:difficulty-corr}
\end{table}


We can also take a look at the responses normalized to $0$ and $1$ where $1$ means
the response was at least $4$. Looking at \autoref{tab:norm-corr}, we can see that players
tend to consider the game difficult if they lost and vice versa.

\begin{table}[h]
	\centering
	\begin{tabular}{lrrrrrrr}
		\toprule
		{} &  balanced &  challenge &  unsure &  smart &  difficult &  strategy &   won \\
		\midrule
		balanced  &      1.00 &       0.35 &    0.53 &   0.21 &       0.07 &      0.22 &  0.15 \\
		challenge &      0.35 &       1.00 &    0.30 &   0.42 &       0.48 &      0.36 & -0.20 \\
		unsure    &      0.53 &       0.30 &    1.00 &   0.17 &       0.16 &      0.14 &  0.07 \\
		smart     &      0.21 &       0.42 &    0.17 &   1.00 &       0.49 &      0.79 & -0.32 \\
		difficult &      0.07 &       0.48 &    0.16 &   0.49 &       1.00 &      0.42 & \cellcolor{blue!25}-0.62 \\
		strategy  &      0.22 &       0.36 &    0.14 &   0.79 &       0.42 &      1.00 & -0.22 \\
		won       &      0.15 &      -0.20 &    0.07 &  -0.32 &      -0.62 &     -0.22 &  1.00 \\
		\bottomrule
	\end{tabular}
	\caption{Table of correlations after normalizing reponse values from 1--7 to 0--1 where 1 means the original response was at least 0.}
	\label{tab:norm-corr}
\end{table}

The total win rate of the players was only $38\%$, which shows that our MCTS~AI
is a formidable opponent. \autoref{tab:means} show the mean of the other responses.

\begin{table}[h]
	\centering
	\begin{tabular}{lr}
		\toprule
		{} & mean \\ 
		\midrule
		balanced        &       0.60\% \\
		challenge       &       0.71\% \\
		unsure  &       0.57\% \\
		smart   &       0.78\% \\
		difficult       &       0.76\% \\
		strategy        &       0.78\% \\
		\bottomrule
	\end{tabular}
	\caption{Table of mean responses to all the questions in the questionnaire.}
	\label{tab:means}
\end{table}

Looking further at the results, in $4$ out of the $20$ games the players lost $100\%$ of the time,
and in $1$ out of the $20$ games the players won $100\%$ of the time. In the resulting $15$ games
there were both cases when a player won and when a player lost.

Given the number of played games, we can
rule out the AI having a better setup in most of the scenarios. Based on the
results, around $60\%$  of the games were balanced,
which means in the resulting $40\%$ one of the players had an advantage.
We consider this result to be positive as the games were generated without
any human intervention and weren't altered before running the experiment.

Considering that $60\%$ of the generated games are balanced, this would allow
the algorithm to be used offline as is to aid design of game levels with
some manual checking of the resulting games. If one were to design the encounter
completely from scratch to be balanced, it would be very difficult given the number
of variables that need to be optimized.

\section{TODO}

\begin{description}[align=right,labelwidth=3cm]
\item bud zminit ze by to slo delat online s nejaky additional checkem
\item nebo zlepsit fitness aby vyresila patologicke pripady z experimentu?
\end{description}

