\chapter{Experiments}
\label{chapter05}

\section{Comparing AIs against each other}

To compare the strength of our AIs against each other, we simulated 1000 randomly generated games
and had the AIs play against each other. Both teams were generated at random and there was no step taken
to make them balanced. Instead, each AI played both sides of the match. See \autoref{tab:winrates} for results.

\begin{table}[h]
	\centering
	\begin{tabular}{|| c | c c c ||}
		\hline
		& MCTS & Rule & Random \\
		\hline\hline
		MCTS & N/A & 63\% & 88\% \\
		Rule & 37\%& N/A & 82\% \\
		Random & 12\% & 18\% & N/A \\
		\hline
	\end{tabular}
	\caption{Table showing win percentages over 1000 games between our different AI implementations.
	MCTS beats Random 88\% of the time, MCTS beats Rule 63\% of the time, and Rule beats Random 82\% of the time.}
	\label{tab:winrates}
\end{table}

As we can see, both MCTS and the Rule Based AI can beat our Random AI with a significant margin,
and MCTS can also consistently beat the Rule Based AI, despite playing for both generated teams.
From this we conclude that:

\begin{enumerate}
	\item A greedy aggressive strategy doesn't always win, which means the game mechanics are rich enough
	to reward strategic thinking.
	\item Thinking ahead (as MCTS does) provides enough value to be significant in terms of win rate.
\end{enumerate}

\missingfigure{vysledky jiny nez experiment}

\section{Participants}

The participants were all computer science students. All of them had at least
some experience with computer games, and were presented the mechanics of HexMage
before conducting the experiment.

\section{Experiment Design}

The goal of the experiment is to measure two things. One, if the generated
encounters are actually balanced. And two, if the AI is strong enough to pose a
challenge to the player. We will measure the overall winrate of the players,
and also compare how the AI did in games the player considered balanced.

The experiment consists of 20 different games of HexMage. All of the games are
played on the same map that was hand-designed beforehand. This was to allow the
participants to better get familiar with the game and think ahead. The games
are structured so that each player has 2 mages, each with 2 abilities. This was
to reduce the cognitive overhead for the participants and allow them to more easily
adjust to the 20 completely different scenarios.

The first 10 of the 20 games had the player team hand designed, and the
opponent (played by the AI) generated with our PCG algorithm. The remaining 10
games had both teams generated with no manual tweaks or changes. Having some of
the games hand designed allows us to show that the PCG algorithm can balance
against constraints that aren't completely random. A hand designed team might
have features that are rare in the search space. All of the games are played
against the MCTS based AI\@ with a fixed number of iterations.

\section{Questionnaire}

The questions were the following, answered on scale (1 - definitely no, to 7 - definitely yes), showing short codes for \autoref{tab:balance-corr} and \autoref{tab:difficulty-corr}

\begin{description}[]
	\item[Balanced:] The game balanced.
	\item[Challenge:] The game was challenging.
	\item[Unsure:] I wasn't sure who was going to win.
	\item[Smart:] The AI played smart.
	\item[Difficult:] The game was difficult.
	\item[Strategy:] The AI showed strategic thinking.
\end{description}

\section{Results}

\begin{table}[h]
	\centering
	\begin{tabular}{lrr}
		\toprule
		{} &  balanced &    unsure \\
		\midrule
		balanced &  1.000000 &  0.725469 \\
		unsure   &  0.725469 &  1.000000 \\
		\bottomrule
	\end{tabular}
	\caption{Correlation table between people who said the game was balanced and who were unsure about the result.}	
	\label{tab:balance-corr}
\end{table}

\begin{table}[h]
	\centering
	\begin{tabular}{lrrrr}
		\toprule
		{} &  challenge &     smart &  difficult &  strategy \\
		\midrule
		challenge &   1.000000 &  0.613178 &   0.457605 &  0.631885 \\
		smart     &   0.613178 &  1.000000 &   0.392413 &  0.819096 \\
		difficult &   0.457605 &  0.392413 &   1.000000 &  0.386505 \\
		strategy  &   0.631885 &  0.819096 &   0.386505 &  1.000000 \\
		\bottomrule
	\end{tabular}
	\caption{Correlation table between people who said the game was challenging, the AI was smart, the game was difficult to play and the AI showed strategic behavior.}
	\label{tab:difficulty-corr}
\end{table}

\missingfigure{korelacni matice}
\missingfigure{grafy}

The results show that most participants consider our MCTS AI to be strong
enough to provide a challengem which is also proven by the 40\% winrate of
the participants. \todo{aktualizovat cisla}

Given the number of played games \todo{overit, ze jich mame dost} we can
rule out the AI having a better setup in most of the scenarios. Based on the
results, around 35\% \todo{aktualizovat cisla} of the games were balanced,
which means in the resulting 65\% one of the players had an advantage.

We consider this result to be positive as the games were generated without
any human intervention and weren't altered before running the experiment.
\todo{link na appendinx s instrukcema na pregenerovani experimentu}

Considering that 35\% of the generated games are balanced, this would allow
the algorithm to be used offline as is to aid design of game levels with
some manual checking of the resulting games.

If one were to design the encounter completely from scratch to be balanced,
it would be very difficult given the number of variables that need to be
optimized.

\section{TODO}

\begin{description}[align=right,labelwidth=3cm]
\item bud zminit ze by to slo delat online s nejaky additional checkem
\item nebo zlepsit fitness aby vyresila patologicke pripady z experimentu?
\end{description}

